Gizmo {
 onCreate "import sys\nthis = nuke.thisNode()\ninference = nuke.toNode(f\"\{this.name()\}.Inference1\")\nthis\[\"gpuName\"].setValue(inference\[\"gpuName\"].value())\nthis\[\"channelsIn\"].setValue(\"rgba.red, rgba.green, rgba.blue\")\ninference.forceValidate()\nis_enabled = inference\[\"modelFile\"].enabled()\nif (sys.platform.lower() == \"darwin\") and (not inference\[\"useGPUIfAvailable\"].enabled()): this\[\"useGPUIfAvailable\"].setValue(False), this\[\"useGPUIfAvailable\"].setEnabled(False)\nif not is_enabled:\n    for k in this.knobs(): this\[k].setEnabled(False)\nthis\[\"halfPrecision\"].setVisible(this\[\"useGPUIfAvailable\"].enabled())"
 onDestroy "nuke.thisNode()\[\"knobChanged\"].setValue(\"\")"
 knobChanged "this = nuke.thisNode()\nthis\[\"halfPrecision\"].setVisible(this\[\"useGPUIfAvailable\"].value())\nfor i,p in enumerate(\[\"p1\", \"p2\", \"p3\", \"p4\",\"p5\",\"n1\",\"n2\",\"n3\",\"n4\",\"n5\"]):\n    e = (i%5)+1\n    text = \"prompt\" if i < 5 else \"negative\"\n    this.node(\"Inference2\").knob(p).setExpression(\"\{\}.\{\}\{\}\".format(this.name(),text,e))\n    this.node(\"Inference1\").knob(p).setExpression(\"\{\}.\{\}\{\}\".format(this.name(),text,e))"
 addUserKnob {20 Parameters}
 addUserKnob {26 localGPU l "Local GPU:" T ""}
 addUserKnob {26 gpuName l "" -STARTLINE T "NVIDIA GeForce RTX 3090"}
 addUserKnob {6 useGPUIfAvailable l "Use GPU if available" t "Select this to render on the <b>Local GPU</b>, if available.\n\nYou can select this even if no GPU is currently available on your machine. The GPU will then be used whenever the script is opened on a machine which does have a GPU available. You should also select this if you wish to render from the command line with the <b>--gpu</b> option.\n\nIf this node requires full frames from its inputs, and is therefore unable to reduce its memory overhead, it will fall back to the CPU if an attempt to render a frame on the GPU fails due to lack of memory. When this occurs, a warning message will be printed to the console." +STARTLINE}
 useGPUIfAvailable true
 addUserKnob {6 halfPrecision l "Optimize for Speed and Memory" t "Whether to process at half float precision. This speeds up execution and enables the processing of larger images, however there is the risk of artifacts with some trained models." +STARTLINE}
 addUserKnob {26 ""}
 addUserKnob {26 channelsIn l "Channels In:" T "rgba.red, rgba.green, rgba.blue"}
 addUserKnob {26 ""}
 addUserKnob {4 modelSize l "Model Size" M {Base Large}}
 modelSize Large
 addUserKnob {20 positive_prompts n 1}
 positive_prompts 0
 addUserKnob {12 prompt1}
 prompt1 {512 512}
 addUserKnob {12 prompt2}
 prompt2 {-200 0}
 addUserKnob {12 prompt3}
 prompt3 {-300 0}
 addUserKnob {12 prompt4}
 prompt4 {-400 0}
 addUserKnob {12 prompt5}
 prompt5 {-500 0}
 addUserKnob {20 endGroup n -1}
 addUserKnob {20 negative_prompts n 1}
 negative_prompts 0
 addUserKnob {12 negative1}
 negative1 {-100 100}
 addUserKnob {12 negative2}
 negative2 {-200 100}
 addUserKnob {12 negative3}
 negative3 {-300 100}
 addUserKnob {12 negative4}
 negative4 {-400 100}
 addUserKnob {12 negative5}
 negative5 {-500 100}
 addUserKnob {20 endGroup_1 n -1}
 addUserKnob {26 "" +STARTLINE}
 addUserKnob {20 DOC n 1}
 addUserKnob {26 _3 l "" +STARTLINE T "Move positive and negative prompts to positive values to make them have an effect.\nIf they are negative they will not be taken into account"}
 addUserKnob {20 endGroup_2 n -1}
 addUserKnob {26 "" +STARTLINE}
 addUserKnob {26 _1 l "" +STARTLINE T "<span><b>Original Model </b> - <a href=\"https://github.com/facebookresearch/segment-anything\" style=\"color:#666;text-decoration: none;\">Segment Anything</a></span>"}
 addUserKnob {26 _2 l "" +STARTLINE T "<span><b>Ported to cattery by </b> - <a href=\"https://www.linkedin.com/in/pcpedrocabrera/\" style=\"color:#666;text-decoration: none;\">Pedro Cabrera</a></span> \n<span><b>Part of the collection </b> - <a href=\"https://github.com/pedroCabrera/CatteryNodes\" style=\"color:#666;text-decoration: none;\">CatteryNodes</a></span>"}
}
 Input {
  inputs 0
  name Input1
  xpos -148
  ypos 59
 }
set N35225800 [stack 0]
 Inference {
  useGPUIfAvailable {{parent.useGPUIfAvailable}}
  modelFile "\[lsearch -inline \[plugins -all sam_vit_l.cat] *.cat]"
  halfPrecision {{parent.halfPrecision}}
  serialiseKnob {}
  name Inference2
  xpos -61
  ypos 205
 }
push $N35225800
 Inference {
  useGPUIfAvailable {{parent.useGPUIfAvailable}}
  modelFile "\[lsearch -inline \[plugins -all sam_vit_b.cat] *.cat]"
  halfPrecision {{parent.halfPrecision}}
  serialiseKnob {p1:{parent.prompt1} 100;p2:{parent.prompt2} -200;p3:{parent.prompt3} -300;p4:-400 -400;p5:{parent.prompt5} -500;n1:-100 -100;n2:{parent.negative2} -200;n3:{parent.negative3} -300;n4:-400 -400;n5:-500 -500;}
  name Inference1
  xpos -242
  ypos 206
 }
 Switch {
  inputs 2
  which {{parent.modelSize}}
  name Switch1
  xpos -150
  ypos 306
 }
 Output {
  name Output1
  xpos -150
  ypos 423
 }
end_group
